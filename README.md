# CodeGenerator

CodeGeneratorëŠ” ë‹¤ì–‘í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ìƒì„± ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. OpenAI, Anthropic, Google, vLLM ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì„ ì§€ì›í•˜ë©°, Direct, CoT, CodeSIM, MapCoder ë“± ë‹¤ì–‘í•œ í”„ë¡¬í”„íŒ… ì „ëµì„ í†µí•´ ì½”ë“œ ìƒì„± ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

- **ë‹¤ì–‘í•œ ëª¨ë¸ ì§€ì›**: OpenAI, Anthropic, Google, vLLM ë“±
- **Qwen3 ëª¨ë¸ ì§€ì›**: Qwen3.5, Qwen3, Qwen3-Coder ê³„ì—´ ëª¨ë¸ (ì´ 43ê°œ ëª¨ë¸)
- **ë‹¤ì–‘í•œ ì „ëµ**: Direct, CoT, CodeSIM, MapCoder, SelfPlanning, Analogical ë“±
- **ë‹¤ì–‘í•œ ë°ì´í„°ì…‹**: HumanEval, MBPP, LiveCodeBench, APPS, xCodeEval ë“±
- **ì‹¤ì‹œê°„ í‰ê°€**: ì½”ë“œ ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸ ìë™í™”
- **í¬ë¡œìŠ¤ í”Œë«í¼**: Windows, Linux, macOS ì§€ì›

## ğŸ“¦ ì„¤ì¹˜

### 1. ê¸°ë³¸ ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. vLLM ì„¤ì¹˜ í™•ì¸

vLLMì´ ì œëŒ€ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸:

```bash
python -c "import vllm; print('vLLM ì„¤ì¹˜ ì™„ë£Œ')"
```

### 3. CUDA ì„¤ì • í™•ì¸

```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi
nvcc --version

# PyTorch CUDA ì§€ì› í™•ì¸
python -c "import torch; print(f'CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}')"
```

## ğŸ¯ ì‚¬ìš©ë²•

### 1. Qwen3 ëª¨ë¸ í‰ê°€ (vLLM) - ê¶Œì¥

#### ê¸°ë³¸ ì‚¬ìš©ë²•
```bash
# Direct ì „ëµìœ¼ë¡œ Qwen3-0.6B í‰ê°€
python run_qwen_evaluation.py \
    --model Qwen3-0.6B \
    --dataset HumanEval \
    --strategy Direct
```

#### CodeSIM ì „ëµ ì‚¬ìš©
```bash
# CodeSIM ì „ëµìœ¼ë¡œ í‰ê°€ (ì½”ë“œ ì „ìš© ëª¨ë¸ ê¶Œì¥)
python run_qwen_evaluation.py \
    --model Qwen3-0.6B \
    --dataset HumanEval \
    --strategy CodeSIM \
    --max_plan_try 5 \
    --max_debug_try 5 \
    --additional_info_run 0
```

#### ë‹¤ì–‘í•œ ì „ëµ ì‚¬ìš©
```bash
# MapCoder ì „ëµ
python run_qwen_evaluation.py \
    --model Qwen3-0.6B \
    --dataset HumanEval \
    --strategy MapCoder

    # CoT (Chain of Thought) ì „ëµ
    python run_qwen_evaluation.py \
        --model Qwen3-0.6B \
        --dataset HumanEval \
        --strategy CoT

    # SelfPlanning ì „ëµ
    python run_qwen_evaluation.py \
        --model Qwen3-0.6B \
        --dataset HumanEval \
        --strategy SelfPlanning
```

#### LiveCodeBench ë°ì´í„°ì…‹
```bash
# LiveCodeBench ë°ì´í„°ì…‹ìœ¼ë¡œ í‰ê°€
python run_qwen_evaluation.py \
    --model Qwen3-0.6B \
    --dataset LiveCodeBench \
    --strategy CodeSIM \
    --temperature 0.1 \
    --max_tokens 4096 \
    --tensor_parallel_size 2
```

### 2. ê¸°ì¡´ main.py ì‚¬ìš©

```bash
# vLLMìœ¼ë¡œ Qwen3-0.6B í‰ê°€
python src/main.py \
    --model Qwen3-0.6B \
    --model_provider vllm \
    --dataset HumanEval \
    --strategy Direct \
    --temperature 0 \
    --top_p 0.95

# CodeSIM ì „ëµ ì‚¬ìš©
python src/main.py \
    --model Qwen3-0.6B \
    --model_provider vllm \
    --dataset HumanEval \
    --strategy CodeSIM \
    --temperature 0 \
    --top_p 0.95
```

### 3. ë‹¤ë¥¸ ëª¨ë¸ë“¤

```bash
# OpenAI GPT-4
python src/main.py \
    --model gpt-4 \
    --model_provider OpenAI \
    --dataset HumanEval \
    --strategy Direct

# Anthropic Claude-3-Sonnet
python src/main.py \
    --model claude-3-sonnet \
    --model_provider anthropic \
    --dataset HumanEval \
    --strategy Direct

# Google Gemini Pro
python src/main.py \
    --model gemini-pro \
    --model_provider Google \
    --dataset HumanEval \
    --strategy Direct
```

## ğŸ—ï¸ ì§€ì› ëª¨ë¸

### Qwen3 ê³„ì—´ (vLLM)
ì•„ë˜ ëª¨ë¸ëª…ì€ ì‹¤ì œ ì§€ì›ë˜ëŠ” ëª¨ë¸ëª…ê³¼ ì¼ì¹˜í•´ì•¼ í•˜ë©°, `src/constants/qwen_models.py` ê¸°ì¤€ì…ë‹ˆë‹¤.

#### Qwen3 ì‹œë¦¬ì¦ˆ
- Qwen3-0.6B
- Qwen3-1.7B
- Qwen3-4B
- Qwen3-8B
- Qwen3-14B
- Qwen3-32B
- Qwen3-30B-A3B (MoE)
- Qwen3-235B-A22B (MoE)

#### Qwen3-Coder ì‹œë¦¬ì¦ˆ
- Qwen3-Coder-30B-A3B-Instruct (MoE, ì½”ë“œ íŠ¹í™”)
- Qwen3-Coder-480B-A35B-Instruct (MoE, ì½”ë“œ íŠ¹í™”)

### ê¸°íƒ€ ëª¨ë¸
- **OpenAI**: GPT-3.5-turbo, GPT-4, GPT-4o, GPT-4o-mini ë“±
- **Anthropic**: Claude-3-Haiku, Claude-3-Sonnet, Claude-3-Opus ë“±
- **Google**: Gemini Pro, Gemini Flash, Gemini 1.5 Pro ë“±
- **Groq**: Llama3-8B, Llama3-70B, Mixtral-8x7B ë“±

## ğŸ­ ì§€ì› ì „ëµ

### ì§€ì› í”„ë¡¬í”„íŒ… ì „ëµ
- **Direct**: ì§ì ‘ ì½”ë“œ ìƒì„± (ê°€ì¥ ë¹ ë¥´ê³  íš¨ìœ¨ì )
- **CoT**: Chain of Thought (ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •)
- **SelfPlanning**: ìì²´ ê³„íš ìˆ˜ë¦½ ë° ì‹¤í–‰
- **CodeSIM**: ì½”ë“œ ì‹œë®¬ë ˆì´ì…˜, ê³„íš ìˆ˜ë¦½, ë””ë²„ê¹… (ê°€ì¥ ì •í™•í•¨)
- **MapCoder**: ë§µí•‘ ê¸°ë°˜ ì½”ë“œ ìƒì„±
- **Analogical**: ìœ ì‚¬ ì‚¬ë¡€ ê¸°ë°˜ ìƒì„±

#### CodeSIM ë³€í˜• ì „ëµ
- **CodeSIMWD**: CodeSIM with Debugging
- **CodeSIMWPV**: CodeSIM with Planning and Validation
- **CodeSIMWPVD**: CodeSIM with Planning, Validation and Debugging
- **CodeSIMA**: CodeSIM Advanced
- **CodeSIMC**: CodeSIM Compact

## ğŸ“Š ì§€ì› ë°ì´í„°ì…‹


### 1. Qwen3 ëª¨ë¸ í‰ê°€ (vLLM) - ê¶Œì¥

#### ê¸°ë³¸ ì‚¬ìš©ë²•
```bash
# Direct ì „ëµìœ¼ë¡œ Qwen3-0.6B í‰ê°€
python run_qwen_evaluation.py \
    --model Qwen3-0.6B \
    --dataset HumanEval \
    --strategy Direct
```

#### CodeSIM ì „ëµ ì‚¬ìš©
```bash
# CodeSIM ì „ëµìœ¼ë¡œ í‰ê°€ 
python run_qwen_evaluation.py \
    --model Qwen3-0.6B \
    --dataset HumanEval \
    --strategy CodeSIM \
    --max_plan_try 5 \
    --max_debug_try 5 \
    --additional_info_run 0
```

#### ë‹¤ì–‘í•œ ì „ëµ ì‚¬ìš©
```bash
# MapCoder ì „ëµ
python run_qwen_evaluation.py \
    --model Qwen3-0.6B \
    --dataset HumanEval \
    --strategy MapCoder

# CoT (Chain of Thought) ì „ëµ
python run_qwen_evaluation.py \
    --model Qwen3-0.6B \
    --dataset HumanEval \
    --strategy CoT

# SelfPlanning ì „ëµ
python run_qwen_evaluation.py \
    --model Qwen3-0.6B \
    --dataset HumanEval \
    --strategy SelfPlanning
```
â”‚   â”‚   â”œâ”€â”€ OpenAI.py            # OpenAI ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ Anthropic.py         # Anthropic ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ VLLMModel.py         # vLLM ëª¨ë¸ (Qwen3 ì§€ì›)
â”‚   â”‚   â”œâ”€â”€ Gemini.py            # Google Gemini ëª¨ë¸
â”‚   â”‚   â””â”€â”€ ModelFactory.py      # ëª¨ë¸ íŒ©í† ë¦¬
â”‚   â”œâ”€â”€ promptings/               # í”„ë¡¬í”„íŒ… ì „ëµ
â”‚   â”‚   â”œâ”€â”€ Base.py              # ê¸°ë³¸ ì „ëµ í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ Direct.py            # Direct ì „ëµ
â”‚   â”‚   â”œâ”€â”€ CodeSIM.py           # CodeSIM ì „ëµ
â”‚   â”‚   â”œâ”€â”€ MapCoder.py          # MapCoder ì „ëµ
â”‚   â”‚   â””â”€â”€ PromptingFactory.py  # ì „ëµ íŒ©í† ë¦¬
â”‚   â”œâ”€â”€ datasets/                 # ë°ì´í„°ì…‹ ë¡œë”
â”‚   â”‚   â”œâ”€â”€ HumanEvalDataset.py  # HumanEval ë°ì´í„°ì…‹
â”‚   â”‚   â”œâ”€â”€ LiveCodeBenchDataset.py # LiveCodeBench ë°ì´í„°ì…‹
â”‚   â”‚   â””â”€â”€ DatasetFactory.py    # ë°ì´í„°ì…‹ íŒ©í† ë¦¬
â”‚   â”œâ”€â”€ evaluations/              # í‰ê°€ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ func_evaluate.py     # í•¨ìˆ˜ í‰ê°€
â”‚   â”‚   â””â”€â”€ resource_limit.py    # ë¦¬ì†ŒìŠ¤ ì œí•œ
â”‚   â”œâ”€â”€ constants/                # ìƒìˆ˜ ì •ì˜
â”‚   â”‚   â”œâ”€â”€ qwen_models.py       # Qwen3 ëª¨ë¸ ì„¤ì •
â”‚   â”‚   â””â”€â”€ paths.py             # ê²½ë¡œ ìƒìˆ˜
â”‚   â”œâ”€â”€ utils/                    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â”‚   â”œâ”€â”€ summary.py           # ê²°ê³¼ ìš”ì•½
â”‚   â”‚   â””â”€â”€ parse.py             # íŒŒì‹± ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ results/                  # ê²°ê³¼ ì²˜ë¦¬
â”‚   â”‚   â””â”€â”€ Results.py           # ê²°ê³¼ í´ë˜ìŠ¤
â”‚   â””â”€â”€ main.py                  # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ data/                         # ë°ì´í„°ì…‹ íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ HumanEval/               # HumanEval ë°ì´í„°
â”‚   â”œâ”€â”€ MBPP/                    # MBPP ë°ì´í„°
â”‚   â”œâ”€â”€ LiveCodeBench/           # LiveCodeBench ë°ì´í„°
â”‚   â””â”€â”€ APPS/                    # APPS ë°ì´í„°
â”œâ”€â”€ results/                      # í‰ê°€ ê²°ê³¼ (ìë™ ìƒì„±)
â”œâ”€â”€ run_qwen_evaluation.py       # Qwen3 ëª¨ë¸ í‰ê°€ í†µí•© ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ test_setup.py                # ì„¤ì • í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt              # Python ì˜ì¡´ì„±
â””â”€â”€ README.md                     # ì´ íŒŒì¼
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì„¤ì¹˜ ë° ì„¤ì •

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-username/CodeGenerator.git
cd CodeGenerator

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# ì„¤ì • í…ŒìŠ¤íŠ¸
python test_setup.py
```

### 2. ì²« ë²ˆì§¸ í‰ê°€ ì‹¤í–‰

```bash
# Qwen3-0.6Bë¡œ HumanEval í‰ê°€
python run_qwen_evaluation.py \
    --model Qwen3-0.6B \
    --dataset HumanEval \
    --strategy Direct
```

### 3. ê²°ê³¼ í™•ì¸

```bash
# ê²°ê³¼ ë””ë ‰í† ë¦¬ í™•ì¸
ls results/

# ìš”ì•½ íŒŒì¼ í™•ì¸
cat results/Qwen3-0.6B_HumanEval_Direct_*/Summary.txt
```

## ğŸ¯ ê³ ê¸‰ ì‚¬ìš©ë²•

### ë°°ì¹˜ í‰ê°€

ì—¬ëŸ¬ ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ í‰ê°€:

```bash
# ì—¬ëŸ¬ ëª¨ë¸ í‰ê°€
for model in "Qwen3-8B" "Qwen3-14B" "Qwen3-32B"; do
    python run_qwen_evaluation.py \
        --model $model \
        --dataset HumanEval \
        --strategy Direct
done
```

### ë‹¤ì–‘í•œ ì „ëµ ë¹„êµ

```bash
# ê°™ì€ ëª¨ë¸ë¡œ ë‹¤ë¥¸ ì „ëµ ë¹„êµ
for strategy in "Direct" "CoT" "CodeSIM" "MapCoder"; do
    python run_qwen_evaluation.py \
        --model Qwen3-Coder-7B \
        --dataset HumanEval \
        --strategy $strategy
done
```

### ì„±ëŠ¥ ìµœì í™”

```bash
# GPU ë©”ëª¨ë¦¬ ìµœì í™”
python run_qwen_evaluation.py \
    --model Qwen3-Coder-7B \
    --dataset HumanEval \
    --strategy Direct \
    --gpu_memory_utilization 0.8 \
    --max_tokens 1024

# ë‹¤ì¤‘ GPU ì‚¬ìš©
python run_qwen_evaluation.py \
    --model Qwen3-Coder-14B \
    --dataset HumanEval \
    --strategy Direct \
    --tensor_parallel_size 2
```

## ğŸ” ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¡°ì •
--gpu_memory_utilization 0.7

    # ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
    --model Qwen3-0.6B

# ìµœëŒ€ í† í° ìˆ˜ ì¤„ì´ê¸°
--max_tokens 1024
```

#### 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```bash
# Hugging Face í† í° ì„¤ì •
export HF_TOKEN=your_token_here

# ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ ì¦ê°€
export HF_HUB_DOWNLOAD_TIMEOUT=1000
```

#### 3. vLLM ì´ˆê¸°í™” ì‹¤íŒ¨
```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi
nvcc --version

# vLLM ì¬ì„¤ì¹˜
pip uninstall vllm
pip install vllm

# PyTorch ì¬ì„¤ì¹˜
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### 4. CodeSIM ì‹¤í–‰ ì˜¤ë¥˜
```bash
# ë” ì‘ì€ ë°°ì¹˜ í¬ê¸°
--max_tokens 1024

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¤„ì´ê¸°
--gpu_memory_utilization 0.7
```

## ğŸ“Š ê²°ê³¼ ë¶„ì„

### ê²°ê³¼ íŒŒì¼ êµ¬ì¡°

```
results/
â””â”€â”€ Qwen_Qwen3-Coder-7B_HumanEval_Direct_20241201_143022/
    â”œâ”€â”€ Results.jsonl          # ìƒì„¸ í‰ê°€ ê²°ê³¼
    â”œâ”€â”€ Summary.txt            # ê²°ê³¼ ìš”ì•½
    â”œâ”€â”€ Log.txt               # ì‹¤í–‰ ë¡œê·¸
    â”œâ”€â”€ Results-ET.jsonl      # Execution Time ê²°ê³¼
    â””â”€â”€ Summary-ET.txt        # Execution Time ìš”ì•½
```